{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgement\n",
    "\n",
    "Many thanks to the references from:\n",
    "\n",
    "- [Autoencoder 自编码](https://morvanzhou.github.io/tutorials/machine-learning/keras/2-6-autoencoder/)\n",
    "- [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Program Setup\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "1. use MNIST\n",
    "2. split the data into train, test set\n",
    "3. normalization\n",
    "4. reshape the data from (60000, 28, 28) to (60000, 784) as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called\n",
    "# X shape (60,000 28x28), y shape (10,000, )\n",
    "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# data pre-processing\n",
    "x_train = x_train.astype('float32') / 255      # normalize all values between 0 and 1\n",
    "x_test = x_test.astype('float32') / 255         # normalize all values between 0 and 1\n",
    "print(x_train.shape) # (60000, 28, 28）\n",
    "print(x_test.shape) # (10000, 28, 28）\n",
    "\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], -1))\n",
    "x_test = x_test.reshape((x_test.shape[0], -1))\n",
    "print(x_train.shape) # (60000, 784)\n",
    "print(x_test.shape) # (10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: How to train a full Auto-encoder model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.3327 - val_loss: 0.2647\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.2603 - val_loss: 0.2564\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.2521 - val_loss: 0.2454\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.2368 - val_loss: 0.2262\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.2194 - val_loss: 0.2087\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.2043 - val_loss: 0.1982\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1966 - val_loss: 0.1914\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1897 - val_loss: 0.1861\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1832 - val_loss: 0.1788\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1772 - val_loss: 0.1733\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1723 - val_loss: 0.1694\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1675 - val_loss: 0.1634\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1632 - val_loss: 0.1605\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1595 - val_loss: 0.1563\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1559 - val_loss: 0.1529\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.1526 - val_loss: 0.1504\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.1497 - val_loss: 0.1482\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1473 - val_loss: 0.1456\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1451 - val_loss: 0.1433\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1434 - val_loss: 0.1421\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1418 - val_loss: 0.1418\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1406 - val_loss: 0.1386\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.1393 - val_loss: 0.13830s - loss: 0.1\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.1381 - val_loss: 0.1359\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.1370 - val_loss: 0.1362\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 11s 192us/step - loss: 0.1356 - val_loss: 0.1345\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.1345 - val_loss: 0.1328\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.1334 - val_loss: 0.1324\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.1324 - val_loss: 0.1301\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.1315 - val_loss: 0.1301\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.1306 - val_loss: 0.1300\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 7s 113us/step - loss: 0.1295 - val_loss: 0.1275\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.1287 - val_loss: 0.1268\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.1272 - val_loss: 0.1256\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.1263 - val_loss: 0.1236\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1252 - val_loss: 0.1239\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.1242 - val_loss: 0.1230\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1234 - val_loss: 0.1221\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1225 - val_loss: 0.1215\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1217 - val_loss: 0.1197\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1208 - val_loss: 0.1188\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1201 - val_loss: 0.1182\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1196 - val_loss: 0.1170\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1188 - val_loss: 0.1162\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.1183 - val_loss: 0.1172\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1177 - val_loss: 0.1154\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1172 - val_loss: 0.1159\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1166 - val_loss: 0.1150\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.1161 - val_loss: 0.1141\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.1156 - val_loss: 0.1132\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.1151 - val_loss: 0.1140\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.1146 - val_loss: 0.1136\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.1142 - val_loss: 0.1122\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1136 - val_loss: 0.1120\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1132 - val_loss: 0.1109\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.1127 - val_loss: 0.1108\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1122 - val_loss: 0.1108\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.1118 - val_loss: 0.1101\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1113 - val_loss: 0.1102\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1109 - val_loss: 0.1102\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1106 - val_loss: 0.1096\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.1102 - val_loss: 0.1108\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.1098 - val_loss: 0.1087\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1095 - val_loss: 0.1074\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.1091 - val_loss: 0.1069\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1088 - val_loss: 0.1083\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.1085 - val_loss: 0.1073\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1082 - val_loss: 0.1067\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1080 - val_loss: 0.1067\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.1077 - val_loss: 0.1066\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.1074 - val_loss: 0.1069\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 6s 107us/step - loss: 0.1071 - val_loss: 0.1061\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.1069 - val_loss: 0.1058\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1066 - val_loss: 0.1057\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.1063 - val_loss: 0.1059\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 96us/step - loss: 0.1061 - val_loss: 0.1044\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.1060 - val_loss: 0.1043\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.1057 - val_loss: 0.1037\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1054 - val_loss: 0.1050\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1052 - val_loss: 0.1041\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.1050 - val_loss: 0.1049\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.1047 - val_loss: 0.1040\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.1045 - val_loss: 0.1028\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 7s 108us/step - loss: 0.1043 - val_loss: 0.1036\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.1042 - val_loss: 0.1026\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.1038 - val_loss: 0.1023\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 6s 97us/step - loss: 0.1038 - val_loss: 0.1033\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.1036 - val_loss: 0.1017\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.1032 - val_loss: 0.1015\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.1031 - val_loss: 0.1016\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 6s 106us/step - loss: 0.1029 - val_loss: 0.1010\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.1028 - val_loss: 0.1016\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 7s 120us/step - loss: 0.1025 - val_loss: 0.1012TA: 1 - ETA: 0s - loss: 0.102\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.1023 - val_loss: 0.1012\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.1022 - val_loss: 0.1021\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.1019 - val_loss: 0.1009\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.1018 - val_loss: 0.1013\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 6s 103us/step - loss: 0.1016 - val_loss: 0.0999\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.1014 - val_loss: 0.1014\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 7s 119us/step - loss: 0.1012 - val_loss: 0.1002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x183157c748>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect all layers as Keras suggestes:\n",
    "input_img = Input(shape=(784,)) # X Layer\n",
    "encoded = Dense(128, activation='relu')(input_img) # input 784, output 128\n",
    "encoded = Dense(64, activation='relu')(encoded) # input 128, output 64\n",
    "encoded = Dense(32, activation='relu')(encoded) # input 64, output 32\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded) # input 32, output 64\n",
    "decoded = Dense(128, activation='relu')(decoded) # input 64, output 128\n",
    "decoded = Dense(784, activation='sigmoid')(decoded) # input 128, output 784. Y Layer\n",
    "\n",
    "\n",
    "# construct and compile the auto-encoder model\n",
    "autoencoder = Model(input_img, decoded) # decoded is our final connected model\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "# finally train the model (Keras will help for validation)\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Visualize how good is our trained autoencoder model?\n",
    "\n",
    "\n",
    "\n",
    "`decoder_layer = autoencoder.layers[-1] # retrieve the last layer of the autoencoder model`\n",
    "only works for single-layer because only last layer is decoder in this case.\n",
    "\n",
    "See [Stackoverflow](https://stackoverflow.com/questions/44472693/how-to-decode-encoded-data-from-deep-autoencoder-in-keras-unclarity-in-tutorial) for more details.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder part\n",
    "encoder = Model(input_img, encoded)\n",
    "\n",
    "# decoder part\n",
    "encoding_dim = 32\n",
    "encoded_input = Input(shape=(encoding_dim,)) # Input layers to a `Model` must be `InputLayer` objects, not tensor\n",
    "\n",
    "decoder = autoencoder.layers[-3](encoded_input)\n",
    "decoder = autoencoder.layers[-2](decoder)\n",
    "decoder = autoencoder.layers[-1](decoder)\n",
    "decoder = Model(encoded_input, decoder) # Keras Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHEAAADqCAYAAAAlBtnSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1830973080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test on all test data\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "# or you may use \n",
    "# decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "# We will only display some(n) of them\n",
    "n = 10  \n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
